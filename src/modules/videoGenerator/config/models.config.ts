import { Markup } from 'telegraf'
import type { ReplyKeyboardMarkup } from 'telegraf/types'

// models.config.ts
export type VideoModelConfig = {
  id: string
  title: string
  description: string
  inputType: ('text' | 'image' | 'morph')[]
  basePrice: number
  api: {
    model: string
    input: Record<string, any>
  }
  requirements?: {
    minBalance?: number
    maxDuration?: number
  }
  imageKey?: string
  canMorph?: boolean
}

export const VIDEO_MODELS_CONFIG: Record<string, VideoModelConfig> = {
  minimax: {
    id: 'minimax',
    title: 'Minimax',
    inputType: ['text', 'image'],
    description: '–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è',
    basePrice: 0.5,
    api: {
      model: 'minimax/video-01',
      input: {
        prompt_optimizer: true,
      },
    },
    imageKey: 'first_frame_image',
  },
  'haiper-video-2': {
    id: 'haiper-video-2',
    title: 'Haiper Video 2',
    description: '–í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å 6 —Å–µ–∫—É–Ω–¥',
    inputType: ['text', 'image'],
    basePrice: 0.05,
    api: {
      model: 'haiper-ai/haiper-video-2',
      input: {
        duration: 6,
        aspect_ratio: (userAspect: string) =>
          userAspect === '9:16' ? '9:16' : '16:9',
        use_prompt_enhancer: true,
      },
    },
    imageKey: 'frame_image_url',
  },
  'ray-v2': {
    id: 'ray-v2',
    title: 'Ray-v2',
    description: '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏',
    inputType: ['text', 'image'],
    basePrice: 0.18,
    api: {
      model: 'luma/ray-2-720p',
      input: {},
    },
    imageKey: 'start_image_url',
  },
  'wan-image-to-video': {
    id: 'wan-image-to-video',
    title: 'Wan-2.1-i2v',
    inputType: ['image'],
    description: '–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è',
    basePrice: 0.25,
    api: {
      model: 'wavespeedai/wan-2.1-i2v-720p',
      input: {
        fast_mode: 'Balanced',
        num_frames: 81,
        sample_shift: 5,
        sample_steps: 30,
        frames_per_second: 16,
        sample_guide_scale: 5,
        max_area: '720x1280',
      },
    },
    imageKey: 'image',
  },
  'wan-text-to-video': {
    id: 'wan-text-to-video',
    title: 'Wan-2.1',
    inputType: ['text'],
    description: '–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è',
    basePrice: 0.25,
    api: {
      model: 'wavespeedai/wan-2.1-t2v-720p',
      input: {
        fast_mode: 'Balanced',
        num_frames: 81,
        sample_shift: 5,
        sample_steps: 30,
        frames_per_second: 16,
        sample_guide_scale: 5,
        max_area: '720x1280',
      },
    },
  },
  'kling-v1.6-pro': {
    id: 'kling-v1.6-pro',
    title: 'Kling v1.6 Pro',
    inputType: ['text', 'image', 'morph'],
    description: '–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∞–Ω–∏–º–∞—Ü–∏—è (—Ü–µ–Ω–∞ –∑–∞ —Å–µ–∫—É–Ω–¥—É)',
    basePrice: 0.098,
    api: {
      model: 'kwaivgi/kling-v1.6-pro',
      input: {
        prompt_optimizer: true,
        cfg_scale: 0.5,
      },
    },
    imageKey: 'start_image',
    canMorph: true,
  },
  'kling-v1.6-standard': {
    id: 'kling-v1.6-standard',
    title: 'Kling v1.6 Standard',
    inputType: ['text', 'image'],
    description: '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è Kling (—Ü–µ–Ω–∞ –∑–∞ —Å–µ–∫—É–Ω–¥—É)',
    basePrice: 0.056,
    api: {
      model: 'kwaivgi/kling-v1.6-standard',
      input: {},
    },
    imageKey: 'start_image',
    canMorph: false,
  },
  'kling-v2.0': {
    id: 'kling-v2.0',
    title: 'Kling v2.0',
    inputType: ['text', 'image'],
    description: '–ù–æ–≤–µ–π—à–∞—è –º–æ–¥–µ–ª—å Kling (—Ü–µ–Ω–∞ –∑–∞ —Å–µ–∫—É–Ω–¥—É)',
    basePrice: 0.28,
    api: {
      model: 'kwaivgi/kling-v2.0',
      input: {},
    },
    imageKey: 'start_image',
    canMorph: false,
  },
  'hunyuan-video-fast': {
    id: 'hunyuan-video-fast',
    title: 'Hunyuan Video Fast',
    inputType: ['text'],
    description: '–ë—ã—Å—Ç—Ä–∞—è –∞–Ω–∏–º–∞—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–º–ø—Ç–æ–≤',
    basePrice: 0.2,
    api: {
      model: 'wavespeedai/hunyuan-video-fast',
      input: {
        prompt_optimizer: true,
      },
    },
  },
}

// –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∫–ª—é—á–µ–π –∫–æ–Ω—Ñ–∏–≥–∞
type VideoModelKey = keyof typeof VIDEO_MODELS_CONFIG

// –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á–∏ –∫–æ–Ω—Ñ–∏–≥–∞ –∫–∞–∫ –æ—Å–Ω–æ–≤—É –¥–ª—è —Ü–µ–Ω
export const videoModelPrices: Record<VideoModelKey, number> =
  Object.fromEntries(
    Object.entries(VIDEO_MODELS_CONFIG).map(([key, config]) => {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ basePrice –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
      if (typeof config.basePrice !== 'number') {
        throw new Error(
          `basePrice is missing or not a number for model key: ${key}`
        )
      }
      return [key, config.basePrice]
    })
  ) as Record<VideoModelKey, number>

export const findModelByTitle = (
  title: string,
  type: 'image' | 'text'
): string | undefined => {
  // –ò–∑–º–µ–Ω–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π —Ç–∏–ø –Ω–∞ string | undefined
  console.log('üîç –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É:', {
    inputTitle: title.trim(),
    inputType: type,
  })

  const foundModel = Object.values(VIDEO_MODELS_CONFIG).find(model => {
    const normalizedInput = title.toLowerCase().trim()
    const normalizedModelTitle = model.title.toLowerCase().trim()

    const titleMatch = normalizedModelTitle === normalizedInput
    const typeMatch = model.inputType.includes(type)

    console.log(`üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ "${model.title}" [${model.inputType}]:`, {
      titleMatch,
      typeMatch,
    })

    return titleMatch && typeMatch
  })

  const resultId = foundModel?.id
  console.log('üîé –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞:', resultId || '–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')
  return resultId
}
export const videoModelKeyboard = (
  isRu: boolean,
  inputType: 'text' | 'image'
): Markup.Markup<ReplyKeyboardMarkup> => {
  console.log('üéπ –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –¥–ª—è –≤–∏–¥–µ–æ-–º–æ–¥–µ–ª–µ–π:', {
    description: 'Creating video models keyboard',
    isRu,
    inputType,
  })

  // –§–∏–ª—å—Ç—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ —Ç–∏–ø—É –≤–≤–æ–¥–∞
  const filteredModels = Object.values(VIDEO_MODELS_CONFIG).filter(model => {
    const include = model.inputType.includes(inputType)
    console.log(`üîò –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏:`, {
      description: 'Checking model',
      modelTitle: model.title,
      modelInputTypes: model.inputType,
      matchesInputType: include,
    })
    return include
  })

  console.log('üìã –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏:', {
    description: 'Filtered models',
    models: filteredModels.map(m => ({
      title: m.title,
      inputTypes: m.inputType,
    })),
  })

  // –§–æ—Ä–º–∏—Ä—É–µ–º —Ä—è–¥—ã –∫–Ω–æ–ø–æ–∫ –ø–æ 2 –≤ —Ä—è–¥
  const modelButtons: string[][] = []
  for (let i = 0; i < filteredModels.length; i += 2) {
    const row = [filteredModels[i].title, filteredModels[i + 1]?.title].filter(
      (title): title is string => Boolean(title)
    )

    if (row.length > 0) {
      modelButtons.push(row)
    }
  }

  // –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∫–Ω–æ–ø–∫—É "–ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é"
  const backButtonText = isRu ? '‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é' : '‚¨ÖÔ∏è Back to Menu'
  modelButtons.push([backButtonText])

  // –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
  const keyboard = Markup.keyboard(modelButtons).resize()

  console.log('‚úÖ –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å–æ–∑–¥–∞–Ω–∞:', {
    description: 'Keyboard created',
    buttonRows: modelButtons,
  })
  return keyboard
}
